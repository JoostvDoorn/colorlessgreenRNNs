{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/private/home/gulordava/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from syntactic_testsets.evaluate_utils import query_KenLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he\n"
     ]
    }
   ],
   "source": [
    "lang = \"Hebrew\"\n",
    "short = lang.lower()[:2]\n",
    "print(short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"/private/home/gulordava/colorlessgreen/data/agreement/\" + lang + \"/generated.tab\"\n",
    "lm_file = \"/private/home/gulordava/ngram_lms/\" + lang + \"/\" + short + \".binary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "full_df = pd.read_csv(data_path,sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_test = open(\"temp.tmp\", 'w')\n",
    "for prefix in full_df.prefix + \" \" + full_df.form:\n",
    "    to_test.write(prefix + \"\\n\")\n",
    "to_test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity including OOVs:\t4560.932140738035\n",
      "Perplexity excluding OOVs:\t4445.762576857454\n",
      "OOVs:\t1220\n",
      "Tokens:\t152540\n",
      "Name:query\tVmPeak:2800352 kB\tVmRSS:3824 kB\tRSSMax:2777456 kB\tuser:0.056\tsys:0.94\tCPU:0.997141\treal:2.71059\n"
     ]
    }
   ],
   "source": [
    "result_probs, lines = query_KenLM(lm_file, \"temp.tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df[\"ngram\"] = result_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L__NOUN_NOUN_PROPN_VERB 0.444444444444 0.333333333333\n",
      "R__VERB_NOUN_PUNCT_CCONJ_VERB 0.583333333333 0.5\n",
      "R__NOUN_ADJ_PUNCT_SCONJ_VERB 0.673611111111 0.5625\n",
      "L__NOUN_PROPN_VERB 0.222222222222 0.0\n",
      "R__NOUN_NOUN_PUNCT_SCONJ_VERB 0.587301587302 0.47619047619\n",
      "L__NOUN_VERB_PUNCT_VERB 0.694444444444 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/private/home/gulordava/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  import sys\n",
      "/private/home/gulordava/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>generated</th>\n",
       "      <td>0.616622</td>\n",
       "      <td>3357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original</th>\n",
       "      <td>0.721180</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                acc      \n",
       "               mean  size\n",
       "type                     \n",
       "generated  0.616622  3357\n",
       "original   0.721180   373"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "wide_data = full_df[[\"pattern\",\"constr_id\", \"sent_id\", \"class\", \"ngram\",\"type\"]].pivot_table(columns=(\"class\"),values=(\"ngram\"),index=[\"pattern\",\"constr_id\", \"sent_id\",\"type\"])\n",
    "wide_data[\"acc\"] = wide_data.correct > wide_data.wrong\n",
    "wide_data = wide_data.reset_index()\n",
    "for pattern in set(wide_data[\"pattern\"]):\n",
    "    acc_generated = np.mean(wide_data[wide_data.pattern == pattern][wide_data.type == \"generated\"][\"acc\"])\n",
    "    acc_original = np.mean(wide_data[wide_data.pattern == pattern][wide_data.type == \"original\"][\"acc\"])\n",
    "    if acc_generated > acc_original:\n",
    "        print(pattern, acc_generated, acc_original)\n",
    "\n",
    "wide_data.groupby([\"type\"]).agg({\"acc\":[\"mean\",\"size\"]})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Macro average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.518518518519 0.456790123457\n",
      "0.666666666667 0.62962962963\n",
      "0.611111111111 0.679012345679\n",
      "0.928571428571 0.52380952381\n",
      "0.692307692308 0.547008547009\n",
      "0.923076923077 0.581196581197\n",
      "0.3 0.277777777778\n",
      "0.555555555556 0.543209876543\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for pattern in set(wide_data.pattern):\n",
    "    p = wide_data[wide_data.pattern == pattern]\n",
    "    c_df = []\n",
    "    for constr in set(p.constr_id):\n",
    "        c = p[p.constr_id == constr]\n",
    "        g = c[c.type == \"generated\"]\n",
    "        o = c[c.type == \"original\"]\n",
    "        if len(g) >0  and len(o) > 0:\n",
    "            acc_o = np.mean(o.correct > o.wrong)\n",
    "            acc_g = np.mean(g.correct > g.wrong)\n",
    "\n",
    "            c_df.append((constr, acc_o, acc_g))\n",
    "            \n",
    "    \n",
    "    _, acc_os, acc_gs = zip(*c_df)\n",
    "    print(np.mean(acc_os), np.mean(acc_gs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def macro_acc(data):\n",
    "    wide_data = data[[\"pattern_id\",\"constr_id\", \"sent_id\", \"class\", \"ngram\"]].pivot_table(columns=(\"class\"),values=(\"ngram\"),index=[\"pattern_id\",\"constr_id\", \"sent_id\"])\n",
    "    wide_data[\"acc\"] = wide_data.correct > wide_data.wrong\n",
    "    #acc = 1\n",
    "    return np.mean(wide_data.groupby(\"constr_id\").mean()[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = [4,5,7,15,16,17,18,19,21,23,24,26,27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_acc(full_df[full_df.type == \"generated\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_acc(full_df[full_df.type == \"original\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing average ngram size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7465"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7460"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All original/generated\t2.60423495477\t1.98197194179\n",
      "Target original/generated\t2.59115281501\t1.93550789395\n"
     ]
    }
   ],
   "source": [
    "p = \"\"\n",
    "ns_o_all = []\n",
    "ns_g_all = []\n",
    "ns_o_tg = []\n",
    "ns_g_tg = []\n",
    "\n",
    "for i in range(len(full_df)):\n",
    "    row = full_df.iloc[i]\n",
    "    l = lines[i]\n",
    "    ngram_size_all = [int(f.split()[1]) for f in l.split(\"\\t\")[:-1]]\n",
    "    ngram_size_target = ngram_size_all[-1]\n",
    "    if row.sent_id == 0:\n",
    "        ns_o_all.extend(ngram_size_all)\n",
    "        ns_o_tg.append(ngram_size_target)\n",
    "    else:\n",
    "        ns_g_all.extend(ngram_size_all)\n",
    "        ns_g_tg.append(ngram_size_target)\n",
    "    \n",
    "    \n",
    "print(\"All original/generated\", np.mean(ns_o_all), np.mean(ns_g_all), sep=\"\\t\")\n",
    "print(\"Target original/generated\", np.mean(ns_o_tg), np.mean(ns_g_tg), sep=\"\\t\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%Rpush full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(data.table)\n",
    "full_df = data.table(full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "print(cor(full_df$ngram, full_df$freq))\n",
    "print(cor(full_df[sent_id == 0]$ngram, full_df[sent_id == 0]$freq))\n",
    "cor(full_df[sent_id != 0]$ngram, full_df[sent_id != 0]$freq)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
